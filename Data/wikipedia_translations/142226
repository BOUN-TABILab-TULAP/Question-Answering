Doğrusal olmayan boyut indirgeme
Yüksek boyutlu veri temsil fazla iki ya da üç boyutu gerektiren verilerin anlam, yorumlamak zor olabilir. Sadeleştirme bir yaklaşım varsaymak olduğunu yüksek boyutlu uzayda içinde gömülü bir doğrusal olmayan manifoldu faiz yalan veri. Manifoldu yeterince düşük boyutta ise, veriler, düşük boyutlu uzayda görülebilir.
Aşağıda manifoldu öğrenme ve doğrusal olmayan boyut indirgeme (NLDR) tarihinin önemli algoritmaların bazıları bir özetidir. Bu lineer olmayan boyut indirgeme yöntemlerin çoğu, aşağıda belirtilen lineer yöntemler ile ilgilidir. (Ya yüksek boyutlu uzayda düşük boyutlu gömme ya da tam tersi) bir eşleme sağlayan o, sadece bir görselleştirme vermek o: Doğrusal olmayan yöntemler genel olarak iki gruba ayrılabilir. Makine öğrenme bağlamında, haritalama yöntemleri örüntü tanıma algoritmaları uygulanır, bundan sonra bir ön özellik çıkarma adımı olarak görülebilir. Ise, mesafe ölçümleri - Tipik bir görselleştirme vermek o yakınlık verilerine dayanmaktadır.
NLDR için kullanır.
Her satır bir şey belirli bir örneğini tanımlayan nitelikler (veya özellikleri veya boyutları) bir dizi temsil edecek şekilde, bir matris (veya bir veritabanı tablosundaki) olarak temsil edilen bir veri kümesi düşünün. Niteliklerin sayısı büyükse, o zaman eşsiz olası satır boşluk katlanarak büyüktür. Böylece, boyut daha büyük, daha zor alan örnek olur. Bu, pek çok sorunlara neden olur. Yüksek boyutlu veri üzerinde işlem Algoritmalar çok yüksek zaman karmaşıklığı sahip olma eğilimindedir. Birçok makine öğrenme algoritmaları, örneğin, yüksek boyutlu veri ile mücadele. Bu boyutluluk laneti olarak bilinir hale gelmiştir. Daha az boyutlara veri azaltılması genellikle analiz algoritmaları daha verimli hale getirir ve makine öğrenme algoritmaları daha doğru tahminler yapmak yardımcı olabilir.
İnsanlar genellikle birçok boyutta zorluk kavrama veri var. Bu nedenle, boyutları küçük bir sayıda veri indirgeme görselleştirme için yararlıdır.
veri azaltılmış boyutlu temsilleri genellikle "iç değişken" olarak adlandırılır. Bu açıklama, bu veriler üretilmiştir olan değerler olduğunu ima eder. Örneğin, ölçekli ve değişen miktarlarda döndürülür edilmiş bir 'A' harfi, görüntülerini içeren bir veri kümesi düşünün. Her resim 32x32 piksel vardır. Her bir görüntü 1024 piksel değerlerinin bir vektör olarak temsil edilebilir. Her satır 1024 boyutlu uzayda (bir Hamming boşluk) iki boyutlu bir manifold üzerinde bir örnektir. iki değişken (rotasyon ve ölçek) veri üretmek amacıyla değiştiği çünkü içsel boyutluluk, ikidir. Her durumda aynı olduğundan şekli veya bir 'A' harfi görünümünü hakkında bilgi içsel değişkenlerin parçası değildir. Doğrusal olmayan boyut indirgeme ilişkili bilgiler (harf 'A') atmak ve sadece değişen bilgileri (rotasyon ve ölçek) kurtaracaktır. sağa doğru görüntü bu veri kümesi örnek görüntüler gösterir, ve NLDR algoritması kullanılarak sonuçlanan iki boyutlu nokta bir arsa (boşluk, her girdi görüntüsü gösterilmektedir değildir tasarrufu için) (bu durumda, Manifold Şekillendirici kullanılmıştır) sadece iki boyutta verileri azaltmak için.
PCA (doğrusal boyut indirgeme algoritması) İki boyutta içine bu aynı veri kümesini azaltmak için kullanılır, eğer Buna karşılık, ortaya çıkan değerler çok iyi organize değildir. Bu yüksek boyutlu vektörler, bu manifold, lineer olmayan bir şekilde değişir örneği (her biri bir harf "A ', temsil eder) göstermektedir.
Bu NLDR bilgisayar görme alanında pek çok uygulama alanı vardır, bu nedenle, açık olmalıdır. Örneğin, bir kapalı statik bir ortamda gezinmek için bir kamera kullanan bir robot düşünün. Bu kamera ile elde edilen görüntüler yüksek boyutlu uzayda bir manifold üzerinde örnekler ve robotun konumunu ve yönünü temsil edeceği manifoldu içsel değişkenler olarak kabul edilebilir. Bu yardımcı robotlar ile sınırlı değildir. Dinamik sistemler, robotlar içeren sistemlerin daha genel bir sınıf, bir manifoldu cinsinden tanımlanır. NLDR Aktif araştırmalar bu tür sistemlerin modellenmesi için teknikler geliştirmek ve özerk çalışmasına sağlayacak dinamik sistemler ile ilişkili gözlem manifoldu açılmak istiyor.
Manifold öğrenme algoritmaları.
Daha belirgin manifoldu öğrenme algoritmaları bazıları (yaklaşık kronolojik sırayla) aşağıda listelenmiştir. Bir algoritma genellikle out-of-örneklem uzantısı olarak adlandırılan bir süreçte gömme içine eğitim anda kullanılamaz noktaları eşleştirmek için kullanılan veri, bir "içsel model" öğrenebilirsiniz.
Sammon haritalama.
Sammon haritalama ilk ve en popüler NLDR tekniklerinden biridir.
Kendinden organize haritayı.
kendi kendini düzenleyen haritası (SOM, ayrıca "Kohonen haritası" olarak adlandırılır) ve olasılık varyant üretimsel topografik haritalama (GTM) gömülü uzaydan doğrusal olmayan bir haritalama dayalı bir gizli değişken modeli oluşturmak için gömülü uzayda bir nokta gösterimi kullanın yüksek boyutlu uzayda için. Bu teknikler aynı olasılık modeli etrafında dayalı yoğunluk ağları, üzerinde çalışmak için ilişkilidir.
Anapara eğrileri ve manifoldlar.
Anapara eğrileri ve manifoldlar doğrusal olmayan boyut azaltılması için doğal geometrik çerçeve vermek ve açıkça gömülü manifoldu inşa ve manifoldu üzerine standart geometrik projeksiyon kullanılarak kodlayarak tarafından HKA geometrik yorumunu uzatmak. Bu yaklaşım tezi (1984) Trevor Hastie tarafından önerilen ve birçok yazar tarafından daha da geliştirildi.
Manifoldun "basitlik" sorunu bağımlı olduğunu tanımlamak için nasıl Ancak, genel olarak iç boyutluluk ve / veya manifold düzgünlüğü ile ölçülür. Genellikle, ana manifoldu bir optimizasyon problemine bir çözüm olarak tanımlanır. amaç fonksiyonu veri yaklaşım bir kalite ve manifoldu bükmeye bazı ceza koşullarını içermektedir. popüler ilk yaklaşımlar doğrusal PCA, Kohonen'in SOM veya autoencoders tarafından üretilir. Elastik harita yöntemi "maksimizasyonu" aşamasında fonksiyonel kuadratik enerji minimizasyonu ile ana kollektör öğrenme için beklenti-maksimizasyonu algoritma sağlar.
Autoencoders.
Bir autoencoder kimlik işlevi yaklaştığı eğitilmiş bir ileri beslemeli sinir ağı olduğunu. Yani, aynı vektör değerlerin bir vektör gelen eşleştirmek için eğitilmiştir. Boyut düşürme amaçları için kullanıldığında, ağ gizli tabaka bir ağ birimlerinin sadece az sayıda içeren sınırlıdır. Böylece, ağ boyutlarının az sayıda içine vektör kodlamak ve sonra özgün uzaya geri çözmek için öğrenmek gerekir. Böylece, ağın ilk yarısı düşük boyutlu uzayda yüksek gelen eşleştiren bir model ve yüksek boyutlu uzayda düşük ikinci yarısında haritaları olduğunu. Autoencoders fikri oldukça eski olmasına rağmen, derin autoencoders eğitimi ancak son zamanlarda kısıtlı Boltzmann makineleri ve yığılmış denoising autoencoders kullanımı ile mümkün hale gelmiştir. Gömülü alana yüksek boyutlu bir doğrusal olmayan eşleme öğrenmek için çok boyutlu ölçeklendirme ve Sammon dönüşümler (aşağıya bakınız) esinlenerek stres işlevlerini kullanan NeuroScale algoritması, autoencoders etmektir İlgili. NeuroScale içinde eşleştirmeleri radyal tabanlı fonksiyon ağları dayanmaktadır.
Gauss süreci gizli değişken modelleri.
Gauss süreci gizli değişken modelleri (GPLVM) yüksek boyutlu verilerin düşük boyutlu doğrusal olmayan katıştırma bulmak için Gauss Süreçler (GP) kullanan bir olasılıklı boyut azaltma yöntemleri vardır. Bunlar PCA.The modelinin olasılık formülasyonun bir uzantısı olasılıksal tanımlanır ve latent değişkenler daha sonra marjinal ve parametreler olasılığını en üst düzeye çıkararak elde edilirler. Çekirdek PCA gibi onlar (bir Gauss süreci şeklinde) bir doğrusal olmayan eşleme oluşturmak için bir çekirdek işlevini kullanın. Ancak GPLVM haritalama veri alanı gömülü (latent) uzaydan tam tersi direction.It başlangıçta yüksek boyutlu veri görselleştirme için önerilmiştir ancak uzatıldı çekirdek PCA oysa (yoğunluk ağları ve GTM gibi) 'dir (insan tahmini poz için, örneğin) iki gözlem uzaylar Paylaşılan Gauss Süreci latent Değişken Modeli (SGPLVM) arasında paylaşılan bir manifoldu modeli oluşturmak için iki gözlem alanlar arasında bir doğrusal olmayan eşleme bulmak için kullanılmıştır.
Eğrisel bileşen analizi.
Kıvrık bileşen analizi (CCA) (orijinal uzayda küçük mesafelerde odaklanmak tersine Sammon en eşleme) çıktı uzayda küçük mesafelerde odaklanırken mümkün olduğunca orijinal mesafeleri koruyan çıkış uzayda noktaların konfigürasyonu arar.
Daha sonra yavaş yavaş küçük mesafelere odağı değiştirmek, CCA, iteratif bir öğrenme algoritması olarak, aslında (Sammon algoritması gibi) büyük mesafeler odaklanarak başladığı dikkat edilmelidir. Bu ikisi arasındaki uzlaşma yapılması gerekiyorsa küçük bir mesafe bilgisi, geniş mesafe bilgilerini üzerine yazacaktır.
CCA gerilme fonksiyonu sağ Bregman farklılıkların toplamı ile ilgilidir
Eğrisel mesafe analizi.
CDA manifoldu sığdırmak için kendi kendini örgütleyen bir sinir ağı trenler ve gömme jeodezik mesafeleri korumak istiyor. Bu Eğrisel Bileşen Analizi (Sammon en haritalama genişletilmiş olan) dayanarak, ancak bunun yerine jeodezik mesafeler kullanır.
Diffeomorphic boyut indirgeme.
Diffeomorphic Boyut Azaltma veya "Diffeomap" düşük boyutlu lineer alt uzay üzerine veri taşır pürüzsüz diffeomorphic eşleme öğrenir. yöntemleri, böylece hem ileri ve ters haritalama altında ikili farklılıkları korumak için çalışırken, veri noktalarında başlayacak sahada boyunca akar düşük boyutlu lineer alt uzay sona erecek şekilde pürüzsüz bir zaman endeksli vektör alanı için çözer.
Çekirdek temel bileşen analizi.
Belki manifoldu öğrenme için en yaygın kullanılan algoritma çekirdek PCA olduğunu. Bu temel bileşenler analizi ve çekirdek hile bir kombinasyonudur. PCA FORMULA_1 matris formula_2 kovaryans matrisi hesaplanarak başlıyor
Daha sonra bu matrisin ilk "k" özvektörler üzerine veri yansıtır. Buna karşılık, kpca, daha yüksek boyutlu bir uzayda dönüşür sonra verilerin kovaryans matrisi hesaplanarak başlıyor
Daha sonra sadece PCA gibi, bu matrisin ilk "k" özvektörler üzerine dönüştürülmüş verileri yansıtır. Bu tüm süreç aslında formula_5 bilgisayar olmadan yapılabilir, öyle ki hesaplama uzakta çok faktör çekirdek hile kullanır. Tabii formula_6 bilinen bir karşılık gelen çekirdek sahip olacak şekilde seçilmelidir. Standart çekirdekleri kullanırken kpca bazı sorunlar ile iyi sonuçlar vermez Ne yazık ki, bu, belirli bir problem için iyi bir çekirdek bulmak önemsiz değildir. Örneğin, İsviçre rulo manifoldu bu çekirdekleri ile kötü performans bilinmektedir. Ancak, böyle bir ortamlarda iyi performans diğer bazı yöntemler görebilirsiniz (örn Laplace Eigenmaps, LLE) veri bağımlı çekirdek matrisi oluşturarak çekirdek PCA olarak özel durumlar.
Kpca içsel model var, bu yüzden eğitim anda mevcut değildi onun gömme üzerine noktalarını eşleştirmek için de kullanılabilir.
Isomap.
Isomap klasik Boyutlu Ölçekleme ile Floyd-Warshall algoritmasının bir kombinasyonudur. Klasik Çok Boyutlu Ölçekleme (MDS) tüm noktalar arasında çift-bilge mesafelerin bir matris alır ve her bir nokta için bir pozisyon hesaplar. Isomap çifti bilge mesafeler sadece komşu noktalar arasındaki bilinen varsayar ve diğer tüm noktalar arasındaki çift-bilge mesafeleri hesaplamak için Floyd-Warshall algoritması kullanır. Bu etkin noktaları tüm arasındaki çift-bilge jeodezik mesafelerin tam matris tahmin ediyor. Isomap sonra tüm noktalarda azalmış boyutlu pozisyonları hesaplamak için klasik MDS kullanır.
Simgesel-Isomap bazı doğruluk pahasına, hızını artırmak için işaretlerini kullanan bu algoritma bir çeşididir.
Yerel doğrusal gömme.
Yerel Doğrusal Gömme (LLE) Isomap yaklaşık olarak aynı anda sunuldu. Bu seyrek matris algoritmaları yararlanmak için uygulanan hızlı optimizasyon ve birçok sorun ile daha iyi sonuçlar da dahil olmak üzere Isomap üzerinde birçok avantajı vardır. LLE ayrıca her noktanın en yakın komşuları bir dizi bularak başlar. Daha sonra en iyi komşuları bir lineer kombinasyonu olarak noktasını ifade her noktası için ağırlıkların bir dizi hesaplar. Son olarak, her nokta hala komşularının aynı doğrusal kombinasyonu ile tarif edilmektedir, öyle ki puan düşük boyutlu katıştırma bulmak için bir özvektör tabanlı optimizasyon tekniğini kullanır. LLE çeşitli bölgelerinde örnek yoğunlukları farklı olarak sürüklenen gelen ağırlıkları önlemek için hiçbir sabit birim olmadığından kötü düzgün olmayan örnek yoğunlukları işlemek eğilimindedir. LLE hiçbir iç modeli vardır.
LLE bir noktaya "X" barisentrik koordinatlarını "i X", "j" "komşularına dayanan" hesaplar. Orijinal nokta komşularının, "W" ile "ij" ağırlık matrisi ile verilen lineer kombinasyonu ile yeniden yapılmıştır. imar hatası maliyet fonksiyonunun "E" ("W") tarafından verilir.
point "X" "i" yeniden ederken ağırlıkları "W" "ij X" katkı miktarına gelin bakın '' "j" vardır. maliyet fonksiyonu iki kısıtlar altında minimize edilmiştir:
(A) Her bir veri noktası "X", "Ben noktası" X "" j X "i" "nokta bir komşu değil" eğer sıfır olarak "ij" "W" komşularından sadece yeniden edilir ve böylece uygulanması " "ve
(B) ağırlık matrisi her satır toplamı 1 eşittir.
Orijinal veri noktaları "D" boyutlu uzayda toplanır ve algoritmanın amacı boyutluluğu için, "d", öyle ki "D" »" D "azaltmaktır. Aynı ağırlıkları D i "inci veri noktası" "yeniden yapılandırır" "W" "ij d" boyutlu uzayda "boyutlu uzayda daha aynı noktayı yeniden kullanılacak". Bir mahalle koruyarak haritası Bu fikri üzerine kurulu oluşturulur. "D" boyutlu uzayda her nokta Xi maliyet fonksiyonu minimize ederek, "d" boyutlu uzayda bir nokta Yi üzerine eşleştirilir
Bu maliyet fonksiyonu olarak, bir önceki aksine, ağırlıklar Wij sabit tutulur ve minimizasyon koordinatları optimize Yi noktalarında yapılır. Bu minimizasyon problemi olan alt "d" sıfırdan farklı öz vektörler koordinat bir ortogonal kümesi sağlamak seyrek "N" X "N" öz değer problemi ("N" veri noktalarının sayısı olmak üzere), çözme çözülebilir. Öklid mesafesi ile ölçülen Genel olarak veri noktaları, "K" yakın komşuları yeniden inşa edilir. Böyle bir uygulama için algoritma çapraz doğrulama tarafından seçilebilir tek serbest parametre "K" vardır.
Laplace eigenmaps.
Laplasyen Eigenmaps boyutluluk azaltma gerçekleştirmek için spektral teknikleri kullanır. Bu teknik verileri, yüksek boyutlu bir uzayda düşük boyutlu manifoldu yatıyor temel varsayımına dayanır. Bu algoritma örnek puan üzerinden embed edemez, ama Çoğaltılması çekirdek Hilbert uzayı regularization dayalı teknikler bu özelliği eklemek için mevcuttur. Bu teknikler hem de diğer lineer olmayan boyut indirgeme algoritmaları uygulanabilir.
Temel bileşenler analizi gibi geleneksel teknikler verinin içsel geometrisini düşünmüyoruz. Laplace eigenmaps veri setinin mahalle bilgilerinden bir grafik oluşturur. Düğümler arasındaki Grafikteki ve bağlantısı üzerinde bir düğüm komşu noktaların yakınlığı tarafından yönetilir gibi her veri noktası (k-en yakın komşu algoritması, örneğin kullanarak) hizmet vermektedir. Bu şekilde üretilen grafik yüksek boyutlu uzayda düşük boyutlu bir manifold ayrı bir yaklaşım olarak kabul edilebilir. Grafikte göre maliyet fonksiyonunun en aza indirilmesi manifoldu üzerinde birbirine yakın noktaları yerel mesafeleri korumak, düşük boyutlu uzayda birbirine yakın eşlenen sağlar. ılımlı koşullar altında bu operatör (birim çember manifoldu üzerinde Fourier serilerinin karşılaştırmak) manifold kare integrallenebilir fonksiyonlar için bir temel oluşturmaktadır sayılabilir spektrumu vardır çünkü manifoldu üzerinde Laplace-Beltrami operatörün özfonksiyonları, gömme boyutları olarak hizmet vermektedir. Katı teorik zeminde Laplace eigenmaps yerleştirmek için girişimleri belirli Sınırlayıcı olmayan varsayımlar altında olduğu gibi, grafik Laplace matris noktalarının sayısı sonsuza gider gibi Laplace-Beltrami operatörü yakınsama gösterilmiştir, bazı başarı ile tanıştım. Laplasyen Eigenmaps için Matlab kodu algoritmaları bulunabilir ve Belkin Doktora tezi Ohio State Üniversitesi'nde bulunabilir.
Sınıflandırma uygulamalarında, düşük boyuta manifoldları görülen durumlarda kümelerinden tanımlanabilir veri sınıflarını modellemek için de kullanılabilir. Her gözlenen örneği 'içerik' sınıf ve 'stil' özüne değişmeyen faktör örnekleri arasında bu sınıfta varyasyonları ifade 'içeriği' ve 'stil' olarak adlandırılan iki bağımsız faktörler tarafından tarif edilebilir. Ne yazık ki, Laplasyen Eigenmaps eğitim verileri tarzı açısından signi fi altıncı saatteki değişen durumlarda oluşur zaman ilgi bir sınıfın tutarlı bir temsilini üretmek için başarısız olabilir. Çok değişkenli dizileri ile temsil edilen sınıfların durumunda, Yapısal Laplace Eigenmaps iyi re fl ect sınıfının içsel yapısı Laplace Eigenmaps mahalle bilgileri grafiğin içinde ek kısıtlamalar ekleyerek bu sorunu aşmak için ileri sürülmüştür. Daha özel olarak ise, grafik, tekrarları içeriyorsa, stil varyasyonları, farklı dizilerin veri noktaları arasında ya da bir sekans dahilinde yakınlık en aza indirmek için, çok değişkenli dizilerin sıralı yapı hem kodlamak için kullanılır ve bu. Dinamik zaman çözgü kullanarak, yakınlık arasındaki yüksek benzerlik sergileyen değişkenli dizilerin bölümleri içinde fi nding yazışmalar tarafından tespit edilir. Vizyon temelli etkinlik tanıma, nesne yönelimi sınıflandırması ve insan 3D üzerinde yapılan deneylerde kurtarma uygulamaları çok değişkenli dizi veri ile uğraşırken Yapısal Laplace Eigenmaps katma değerini göstermek zorunda oluşturmaktadır. Yapısal Laplace Eigenmaps, Genelleştirilmiş Laplace Eigenmaps bir uzantısı boyutlardan biri, özellikle tarzında varyasyonları temsil manifoldlann nesil yol açtı. Bu, insan belden gövde ve siluet ekstraksiyon takip gibi uygulamalarda özellikle değerli olduğu kanıtlanmıştır.
Manifold hizalama.
Manifold hizalama benzer üreten süreçleri tarafından üretilen farklı veri setleri benzer yatan manifoldu temsil paylaşacak varsayımı yararlanır. Paylaşılan manifolduna her orijinal uzaydan projeksiyonlar öğrenerek, yazışmalar kurtarıldı ve bir etki alanından bilgi diğerine transfer edilebilir. Çoğu manifoldu hizalama teknikleri sadece iki veri setini düşünün, ama kavram keyfi çok ilk veri setleri kadar uzanır.
Difüzyon haritaları.
Difüzyon haritaları ısı difüzyon ve rastgele yürüyüş (Markov Zinciri) arasındaki ilişkiyi güçlendirir; bir benzetme, bir manifold üzerinde difüzyon operatörü olan ve düğümleri manifoldundan örneklenmiş grafikte tanımlı fonksiyonlar üzerinde çalışan bir Markov geçiş matrisi arasında çizilir. Özellikle bir veri seti formula_10 ile temsil edilebilir olsun. difüzyon haritanın altında yatan varsayım, yüksek boyutlu olmasına rağmen veriler, veri kümesi ve formula_12 bu tanımlamanızı sağlar ek olarak X üzerinde veri noktalarının dağılımını temsil edelim temsil formula_11.X boyutlarda düşük boyutlu manifoldu üzerinde yatıyor olması X aşağıdaki özelliklere sahiptir formula_13 çekirdek noktalarının yakınlığına bazı kavramını temsil eden bir çekirdek
"K" simetrik
"K" pozitifliği korumak olduğunu
Böylece bir grafik ve grafik üzerinde afinite çeşit tanımlayan çekirdek "k" düğümleri gibi bireysel veri noktaları düşünebilirsiniz. Çekirdek simetrik olduğundan grafik inşaat tarafından simetriktir. Bu başlığın {X k} birer tersinir Markov Zinciri inşa edebilirsiniz burada görmek kolaydır. Bu teknik alanlarda çeşitli oldukça popüler ve grafik Laplacian'ın olarak bilinir.
Grafik K = ("X", "E") bir Gauss çekirdeği kullanılarak, örneğin inşa edilebilir.
Bu yukarıdaki denklem formula_17 içinde formula_19 bir yakın komşu formula_18 olduğunu gösterir. Gerçekte Geodesic mesafe aslında manifoldu üzerinde mesafeleri ölçmek için kullanılmalıdır. Manifoldu tam yapısı mevcut olmadığından, jeodezik mesafe sadece yakın komşuları ile Öklid mesafeleri tarafından yaklaşılır. seçim formula_20 anlamda yakınlığı nosyonumuzu modüle eğer formula_21 daha sonra formula_22 ve gerekirse daha sonra formula_23 formula_24. İkinci difüzyon işlemi neredeyse tamamlandı olduğunu ima ederken çok az difüzyon yerini almıştır eski araçlar. Farklı stratejiler formula_20 bulunabilir seçim formula_26 sadakatle Markov matrisi temsil etmek varsa, o zaman gelen lisans matris formula_27 normalize edilmesi gerekir.:
formula_29 şimdi Markov zinciri temsil eder. formula_30 bir zaman adımı içinde formula_32 için formula_18 geçmekte olasılığıdır. Benzer şekilde T süresi adımda formula_32 için formula_18 arasında geçiş olasılığı formula_35 ile verilir. İşte formula_36 kez t kendisine çarpılır formula_29 matristir. Şimdi Markov matris formula_29 veri seti X difüzyon haritaları ve temel bileşen analizi arasındaki en önemli fark yerel geometri kavramı bazı verilerin yalnızca yerel özellikleri, tüm veri setinin ilişkiyi alarak karşı difüzyon haritalarında kabul edilir yani oluşturan .
formula_26 çekirdek veri setinin bazı yerel geometri yakalar anlamına veri seti üzerinde rasgele yürüyüş tanımlar. Markov zinciri çekirdek tarafından alınan değerlere dayalı yayılma hızlı ve yavaş yön tanımlar ve bir anda ileri yürüyüşe yayar olarak, yerel geometri bilgilerinin (diferansiyel denklemler tarafından tanımlanan) yerel geçişler aynı şekilde agrega dinamik sistem. difüzyon kavramı bir aile difüzyon mesafesi {formula_40} formula_41 tanımından kaynaklanmaktadır
T formula_40 belirli bir değeri için, veri kümesi, herhangi iki nokta arasındaki mesafeyi tanımlar. Bu tersi y için x bağlamak ve birçok yollar varsa formula_44 değeri küçük olacağı anlamına gelir. Miktar formula_44 formula_40 mesafe jeodezik karşı veri gürültü son derece sağlamdır ve bunun bir sonucu olarak, uzunluk t tüm yolların üzerinde toplanmasıyla ilgilidir. formula_40 mesafe hesaplanırken dikkate noktaları x ve y arasındaki tüm ilişkiyi alır ve sadece Öklid mesafesi ve hatta jeodezik mesafeden daha yakın daha iyi bir kavram olarak hizmet vermektedir.
Hessen Yerel Doğrusal Gömme (Hessen LLE).
LLE gibi, Hessen LLE da seyrek matris teknikleri dayanmaktadır. Bu LLE çok daha yüksek bir kalitede sonuçlar eğilimindedir. Ne yazık ki, çok pahalı hesaplama karmaşıklığı vardır, bu yüzden ağır örneklenmiş manifoldlar için çok uygundur değil. Hiçbir içsel model vardır.
Modifiye Yerel Doğrusal Gömme (Mlle).
Modifiye LLE (Mlle) LLE haritalarında çarpıtmalara yol açan yerel ağırlık matrisi klima sorunu çözmek için her mahallede birden fazla ağırlıkları kullanan başka LLE çeşididir. Mlle Hessen LLE benzer sağlam projeksiyonlar oluşturur, ancak önemli ek hesaplama maliyet olmadan.
Yerel tanjant uzay hizalama.
LTSA bir manifold doğru katlanmamış olduğunda, teğet her hizalanmış hale gelecektir manifolduna hiperdüzlemler önsezinin dayanmaktadır. Her nokta "k" -nearest komşu işlem başlar. Her yerel mahallede temel bileşenler Birincilik "d" hesaplayarak her noktada teğet alanı hesaplar. Daha sonra teğet boşluk hizalar bir katıştırma bulmak için optimize eder.
Yerel boyutlu ölçekleme.
Yerel Boyutlu Ölçekleme yerel bölgelerde çok boyutlu ölçekleme yapar ve daha sonra tüm parçaları bir araya sığacak şekilde dışbükey optimizasyon kullanır.
Maksimum varyans açılımı.
Maksimum Varyans eskiden Semidefinite Gömme olarak biliniyordu açılımı. Bu algoritma için sezgi bir manifold düzgün açılınca, puan üzerinden varyans maksimize olmasıdır. Bu algoritma, aynı zamanda her noktanın "k" -nearest komşuları bularak başlar. Daha sonra, tüm komşu olmayan nokta arasındaki mesafeyi maksimize edilmesi sorununu çözmek için çalışmaktadır komşu noktaları arasındaki mesafeler korunur şekilde kısıtlı. Bu algoritmanın temel katkısı semidefinite programlama problemi olarak bu sorunu döküm için kullanılan bir tekniktir. Ne yazık ki, semidefinite programlama çözücüleri yüksek hesaplama maliyeti var. Bu algoritma Landmark-MVU varyantı doğrulukla bazı maliyet hızını artırmak için işaretlerini kullanır. Hiçbir modeli vardır.
Doğrusal Olmayan PCA.
Doğrusal Olmayan PCA (NLPCA) bir manifolda sığdırmak için çok katmanlı algılayıcı yetiştirmek geri yayılım kullanır. Sadece ağırlıkları günceller tipik MLP eğitim aksine, NLPCA ağırlıkları ve girdileri hem de günceller. Yani, ağırlıkları ve girişler hem gizli değerler olarak kabul edilir edilir. Eğitimden sonra, gizli girdiler gözlenen vektörlerin düşük boyutlu gösterimi ve yüksek boyutlu gözlem alana, düşük boyutlu gösteriminden MLP haritalardır.
Veri odaklı yüksek boyutlu ölçekleme.
Veriye Dayalı Yüksek Boyutlu Ölçekleme (GG-HDS) yakından dışında Sammon en haritalama ve eğrisel bileşen analizi ile ilgilidir (1) aynı anda hem orijinal ve çıkış uzayda küçük mesafeler odaklanarak yanlış mahalleleri ve gözyaşları cezalandıran ve bu (2) Bu mesafe dağıtım ağırlık fonksiyonu uyarlayarak tedbir fenomeni konsantrasyonu oluşturmaktadır.
Manifold heykel.
Manifold Şekillendirici kullandığı bir iç içelik bulmak için optimizasyon mezun oldu. Diğer algoritmalar gibi, "k" -nearest komşuları hesaplar ve yerel mahallelerinde ilişkileri koruyan bir iç içelik aramaya çalışır. Aynı anda alt boyutlarda noktaları ayarlayarak bu ilişkileri korumak için ise yavaş yavaş, yüksek boyutlarda dışarı varyansını ölçekler. Ölçekleme oranı küçükse, bu çok hassas katıştırmalarını bulabilirsiniz. Birkaç sorunları olan diğer algoritmalara göre daha yüksek ampirik doğruluk sahiptir. Aynı zamanda diğer manifoldu öğrenme algoritmaları sonuçları daraltmak için kullanılabilir. Bu çok yavaş ölçeklendirme oranı kullanılmadığı sürece, bununla birlikte, bazı manifoldu açılmak için mücadele eder. Hiçbir modeli vardır.
RankVisu.
RankVisu mahalle ziyade mesafe rütbe korumak için tasarlanmıştır. RankVisu zor görevler (mesafenin korunması satisfyingly elde edilemeyen) özellikle yararlıdır. Nitekim, mahalle sıralaması (sıralarında mesafelerden çıkarılabilir ancak mesafeler saflarından çıkaramayız) mesafeden daha az bilgilendirici ve korunması, böylece daha kolaydır.
Topolojik izometrik gömülmesini kısıtlı.
Topolojik Kısıtlı İzometrik Gömme (TCIE) Öklid metrik aykırı jeodezikler filtreleme sonra jeodezik mesafeleri yaklaşan tabanlı bir algoritmadır. Isomap özünde dışbükey verileri eşlemek için kullanıldığında neden bozukluklarının düzeltilmesini hedefleyen TCIE daha doğru bir eşleme elde etmek için ağırlıkça en küçük kareler MDS kullanır. TCIE algoritması ilk veri mümkün sınır noktalarını algılar ve takip ağırlıklı Stres majorlaştırma küçük bir ağırlık verilecek jeodezik uzunluk hesaplaması sırasında, tutarsız jeodezikler işaretler.
İlişkisel perspektif haritası.
İlişkisel perspektif haritası çok boyutlu ölçekleme algoritması. Algoritma veri noktaları parçacıklar ve mesafeler (veya benzemezlik) veri noktaları arasındaki eşleştirilmiş bir itici gücü temsil edilmektedir kapalı manifoldu, bir çok parçacık dinamik bir sistem simüle ederek bir manifold üzerinde veri noktaları yapılandırmasını bulur. Manifoldu, giderek boyut büyüdükçe çok parçacık sistemi yavaş yavaş soğur ve veri noktalarının mesafe bilgisini yansıtan bir yapılandırmaya yakınlaşıyor.
İlişkisel perspektif haritası pozitif yüklü parçacıklar topun yüzeyinde serbestçe hareket ettiği bir fiziksel modeli esinlenilmiştir. Partiküller arasındaki Coulomb kuvveti rehberliğinde, parçacıkların minimum enerji yapılandırması parçacıklar arasındaki itici güçlerin gücünü yansıtır.
İlişkisel perspektif haritası tanıtıldı.
Algoritma öncelikle görüntü manifoldları olarak, küre, projektif uzay ve Klein şişesi gibi, kapalı manifoldları diğer türleri kullanmak için yazılım VisuMap içinde (o uzatıldı, görüntü manifoldu gibi düz torus kullanılır.
Yakınlık matrisler dayalı yöntemler.
Yakınlığı matrisler göre bir yöntem olup veri benzerlik matrisi veya bir mesafe matris formunda algoritmasına sunulmuştur biridir. Bu yöntemler, tüm metrik boyutlu ölçekleme geniş sınıfın altında yer almaktadır. varyasyonlar yakınlık verileri nasıl hesaplandığını farklılıklar olma eğilimindedir; örneğin, Isomap lokal lineer gömmeler maksimum sapma açılma ve (aslında bir eşleme değildir) Sammon eşleme mt boyutlu ölçekleme yöntemler örnek olarak verilebilir.
